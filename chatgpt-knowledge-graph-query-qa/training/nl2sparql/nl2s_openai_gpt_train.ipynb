{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759c2eed-b8c6-475c-9bc3-25d1b60956f6",
   "metadata": {},
   "source": [
    "# Training a gpt 3 model for nl2sparql\n",
    "Openai only supports fine-tuning on their gpt3 models: ada, babbage, curie and davinci. They do not yet support fine-tuning \n",
    "on gpt3.5 (aka chatGPT, aka \"gpt-3.5-turbo\"). This notebook examines the models for which fine-tuninig is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6a6c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/simple, https://artifactory.concurtech.net/artifactory/api/pypi/ext-pypi-selfserve-local/simple\n",
      "Requirement already satisfied: wikibaseintegrator in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (0.12.3)\n",
      "Requirement already satisfied: backoff<2.3.0,>=1.11.1 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from wikibaseintegrator) (2.2.1)\n",
      "Requirement already satisfied: oauthlib~=3.2.0 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from wikibaseintegrator) (3.2.2)\n",
      "Requirement already satisfied: requests<2.29.0,>=2.27.1 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from wikibaseintegrator) (2.28.1)\n",
      "Requirement already satisfied: requests-oauthlib~=1.3.1 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from wikibaseintegrator) (1.3.1)\n",
      "Requirement already satisfied: mwoauth~=0.3.8 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from wikibaseintegrator) (0.3.8)\n",
      "Requirement already satisfied: ujson<5.8,>=5.4 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from wikibaseintegrator) (5.7.0)\n",
      "Requirement already satisfied: PyJWT>=1.0.1 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from mwoauth~=0.3.8->wikibaseintegrator) (2.6.0)\n",
      "Requirement already satisfied: six in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from mwoauth~=0.3.8->wikibaseintegrator) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from requests<2.29.0,>=2.27.1->wikibaseintegrator) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from requests<2.29.0,>=2.27.1->wikibaseintegrator) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from requests<2.29.0,>=2.27.1->wikibaseintegrator) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/anaconda3/envs/conda210/lib/python3.9/site-packages (from requests<2.29.0,>=2.27.1->wikibaseintegrator) (1.26.14)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install wikibaseintegrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68ea383-c1c2-47f4-b220-38dde70c86c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install these as needed\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c03fcf-e86c-4f79-bddb-5ee3ed909a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# these imports should not require installation\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c326be62-3bf6-4917-8e1d-b8e559bf2ab1",
   "metadata": {},
   "source": [
    "### We will need the lcquad data as a DataFrame. You may need to change this file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca887cd9-6f19-4378-aed9-bfc714475700",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcquad_filename = '../../lcquad2.0.train.json'\n",
    "lcquad_df = pd.read_json(lcquad_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6cf112-5db4-4bfb-b636-b7c4f079fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_validate = lcquad_df.sample(n=1200, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed1443d-6e80-48a0-a4b2-bf108385fb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train_validate.sample(n=1000, random_state=2)\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0c40f4-8f05-4cec-bbb9-46f5f0c1da44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validate = df_train_validate.drop(df_train.index)\n",
    "len(df_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1344378-6552-48ea-ae65-e8e153381dc0",
   "metadata": {},
   "source": [
    "Let's validate that these are really distinct samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "125397c1-708f-4280-94a7-acd87d4dabfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = set()\n",
    "s.update(list(df_train.index))\n",
    "s.update(list(df_validate.index))\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d427ff-07ef-4aeb-ab08-0d2a44c8b7d3",
   "metadata": {},
   "source": [
    "### Set up the openai api key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e5309-5c5b-478b-9ba3-57d8e8584981",
   "metadata": {},
   "source": [
    "The api key is a secret and so should not be checked into github. This is what the ini file should look like:\n",
    "```\n",
    "[OPENAI]\n",
    "OPENAI_API_KEY=<openai key here>\n",
    "[WANDB]\n",
    "WANDB_API_KEY=<wandb key here>\n",
    "```\n",
    "Add your own api key there, or ask Max for his."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b41ffed-aa44-48c2-96ba-fdd1c20b7448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['secrets.ini']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('secrets.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607e6281-030f-4187-a969-bbc4f58ac1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.update({'OPENAI_API_KEY': config['OPENAI']['OPENAI_API_KEY']})\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebff0f13-1655-4436-a7d5-b22c0d37bb98",
   "metadata": {},
   "source": [
    "### Sanity check: openai's tutorial example\n",
    "This is here just to validate that the api setup is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e93c2691-a8bb-4435-879a-ac4f6581691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(animal):\n",
    "    return \"\"\"Suggest three names for an animal that is a superhero.\n",
    "\n",
    "Animal: Cat\n",
    "Names: Captain Sharpclaw, Agent Fluffball, The Incredible Feline\n",
    "Animal: Dog\n",
    "Names: Ruff the Protector, Wonder Canine, Sir Barks-a-Lot\n",
    "Animal: {}\n",
    "Names:\"\"\".format(\n",
    "        animal.capitalize()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bed141c9-97a8-4937-ada0-de4df24ef29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt=\"\", model=\"text-davinci-003\", temperature=0.6, stop=None):\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=100,\n",
    "        stop=stop\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "463c9b9c-5f1a-433a-8572-dfe84cac9bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Mighty Moo-ver, Bovine Brawler, Supercow!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = run_prompt(generate_prompt('cow'))\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a0662-9a76-49e3-a433-d751d7c8fa76",
   "metadata": {},
   "source": [
    "### Sanity check: the openai CLI should be working as well\n",
    "Implant the key in the shell environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be28c027-1c88-41ec-9042-df197c4c0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implant the openai key in the shell environment\n",
    "!eval `cat secrets.ini | grep OPENAI_API_KEY | sed 's/^/export /'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95973385-394e-4b21-b6f3-9753aab68f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/bin/openai\n"
     ]
    }
   ],
   "source": [
    "!which openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d98796-569c-4e2f-b78c-4a9e51c5f1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/simple, https://artifactory.concurtech.net/artifactory/api/pypi/ext-pypi-selfserve-local/simple\n",
      "Requirement already satisfied: openai in /opt/homebrew/anaconda3/lib/python3.9/site-packages (0.27.2)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.8.2)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# if the above fails, try this\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f501c328-4a4e-429d-83b5-5273d663154e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"created_at\": 1677959387,\n",
      "      \"fine_tuned_model\": \"ada:ft-personal-2023-03-04-20-06-30\",\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": 1,\n",
      "        \"learning_rate_multiplier\": 0.1,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-90O7QVVHQ86vwYsLsRe3lFbZ\",\n",
      "      \"model\": \"ada\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-6Tm9wvTU2DAyCUVamArcvPxV\",\n",
      "      \"result_files\": [\n",
      "        {\n",
      "          \"bytes\": 43024,\n",
      "          \"created_at\": 1677960391,\n",
      "          \"filename\": \"compiled_results.csv\",\n",
      "          \"id\": \"file-xZCujiVRhZnleRx5KowmvYt7\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune-results\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"status\": \"succeeded\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 37497,\n",
      "          \"created_at\": 1677959386,\n",
      "          \"filename\": \"openai_train.jsonl\",\n",
      "          \"id\": \"file-PtdM8l5yCZybCnRknRIFCIiv\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1677960391,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1677963101,\n",
      "      \"fine_tuned_model\": \"ada:ft-personal-2023-03-04-21-11-21\",\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": 1,\n",
      "        \"learning_rate_multiplier\": 0.1,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-crVxoOxApdG6RYjTGmfgbOKs\",\n",
      "      \"model\": \"ada:ft-personal-2023-03-04-20-06-30\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-6Tm9wvTU2DAyCUVamArcvPxV\",\n",
      "      \"result_files\": [\n",
      "        {\n",
      "          \"bytes\": 87936,\n",
      "          \"created_at\": 1677964281,\n",
      "          \"filename\": \"compiled_results.csv\",\n",
      "          \"id\": \"file-1uvhik2o2oWUGvOPzU5LgabR\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune-results\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"status\": \"succeeded\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 78199,\n",
      "          \"created_at\": 1677963101,\n",
      "          \"filename\": \"openai_train_2.jsonl\",\n",
      "          \"id\": \"file-8ATX53TzUvTHFWmHRYFXUFWp\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1677964281,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1677981602,\n",
      "      \"fine_tuned_model\": \"curie:ft-personal-2023-03-05-02-23-24\",\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": 2,\n",
      "        \"learning_rate_multiplier\": 0.1,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-sxhfek2JYFC1P0dc3qhNZdn5\",\n",
      "      \"model\": \"curie\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-6Tm9wvTU2DAyCUVamArcvPxV\",\n",
      "      \"result_files\": [\n",
      "        {\n",
      "          \"bytes\": 114090,\n",
      "          \"created_at\": 1677983004,\n",
      "          \"filename\": \"compiled_results.csv\",\n",
      "          \"id\": \"file-hvHP4fYjSbfPSaqHSk7kCXfK\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune-results\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"status\": \"succeeded\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 195124,\n",
      "          \"created_at\": 1677981601,\n",
      "          \"filename\": \"curie_train.jsonl\",\n",
      "          \"id\": \"file-zEbf5LEeMeu7qOG5qPJrZAtR\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1677983005,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1678044822,\n",
      "      \"fine_tuned_model\": \"ada:ft-personal-2023-03-05-19-39-25\",\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": 1,\n",
      "        \"learning_rate_multiplier\": 0.1,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-iCN2sLZ7X207KdKTZGhXwGNo\",\n",
      "      \"model\": \"ada\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-6Tm9wvTU2DAyCUVamArcvPxV\",\n",
      "      \"result_files\": [\n",
      "        {\n",
      "          \"bytes\": 43145,\n",
      "          \"created_at\": 1678045166,\n",
      "          \"filename\": \"compiled_results.csv\",\n",
      "          \"id\": \"file-7UXK6O1KZZzvkzsMEqzAAU8Q\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune-results\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"status\": \"succeeded\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 38794,\n",
      "          \"created_at\": 1678044822,\n",
      "          \"filename\": \"openai_train_SZ3K1.jsonl\",\n",
      "          \"id\": \"file-wLPJKzEDfq1u4DupT7D0PDxH\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1678045166,\n",
      "      \"validation_files\": []\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1678049594,\n",
      "      \"fine_tuned_model\": \"ada:ft-personal-2023-03-05-21-03-15\",\n",
      "      \"hyperparams\": {\n",
      "        \"batch_size\": 1,\n",
      "        \"learning_rate_multiplier\": 0.1,\n",
      "        \"n_epochs\": 4,\n",
      "        \"prompt_loss_weight\": 0.01\n",
      "      },\n",
      "      \"id\": \"ft-x7hEyQMoafisWYGmadSSPLWA\",\n",
      "      \"model\": \"ada:ft-personal-2023-03-05-19-39-25\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"organization_id\": \"org-6Tm9wvTU2DAyCUVamArcvPxV\",\n",
      "      \"result_files\": [\n",
      "        {\n",
      "          \"bytes\": 43354,\n",
      "          \"created_at\": 1678050196,\n",
      "          \"filename\": \"compiled_results.csv\",\n",
      "          \"id\": \"file-owhfEUuqduH3kiZ6G0ub7dBW\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune-results\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"status\": \"succeeded\",\n",
      "      \"training_files\": [\n",
      "        {\n",
      "          \"bytes\": 38794,\n",
      "          \"created_at\": 1678049594,\n",
      "          \"filename\": \"openai_train_SZ3K1.jsonl\",\n",
      "          \"id\": \"file-YTD6TqmbQ3ZBH1B5IZSRdJqo\",\n",
      "          \"object\": \"file\",\n",
      "          \"purpose\": \"fine-tune\",\n",
      "          \"status\": \"processed\",\n",
      "          \"status_details\": null\n",
      "        }\n",
      "      ],\n",
      "      \"updated_at\": 1678050196,\n",
      "      \"validation_files\": []\n",
      "    }\n",
      "  ],\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# this is a quick way to validate that the CLI is working\n",
    "!openai api fine_tunes.list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b298d-1a32-4760-81f9-94603f9c7aa7",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "Choose a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06f59c5c-b206-4ef9-93f0-b4ef021f8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = 'ada'\n",
    "#base_model = 'curie'\n",
    "base_model = 'davinci'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da9a28-8c94-40b2-a723-653d59ea62c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Does the model know anything about sparql already?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8201967f-3afd-4709-a809-4c5138e6e649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' that can do this.\\n\\nThanks.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = run_prompt(\"Please show me a sample sparql query\", model=base_model)\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a69fb49a-3bec-46bd-81f3-421e31c5e04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe query is a string that describes a set of triples. The query is run against a sparql endpoint and the results are returned.\\n\\nWhat is sparql?\\n\\nsparql is a query language for the semantic web.\\n\\nWhat is the semantic web?\\n\\nThe semantic web is a web of data that is linked, annotated, and defined by machine-readable standards. It is a web that can be read and understood by machines.\\n\\nWhat'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = run_prompt(\"What does a sparql query do?\", model=base_model)\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a05d0834-de5c-406b-b550-8b9cf116ce72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' in your language.\\n\\nThe query was translated to the following languages:\\n\\nFrench: Delta Air Lines a publiÃ© une revue trimestrielle en anglais.\\n\\nItalian: Delta Air Lines ha pubblicato una rivista trimestrale in inglese.\\n\\nSpanish: Delta Air Lines editÃ³ una revista trimestral en inglÃ©s.\\n\\nGerman: Delta Air Lines publizierte eine hal'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = run_prompt(\"Please translate this question to sparql: 'What is Delta Air Line's periodical literature mouthpiece'\", model=base_model)\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b4ed3-a673-4f6d-a1d0-aaf22fde640e",
   "metadata": {},
   "source": [
    "Openai wants fine-tune data in a certain format. See https://platform.openai.com/docs/guides/fine-tuning/prepare-training-data.\n",
    "This function prepares lcquad data. Note that the script prefers the \"paraphrased\" question. This is something we could play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ebcbfa7-5ec7-4392-8daa-6eeb3bd3ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_finetune_data(df, filename=None):\n",
    "    training_json = []\n",
    "    for index, row in df.iterrows():\n",
    "        d = {}\n",
    "        question = row['paraphrased_question']\n",
    "        if len(question) == 0 or len(question) > 2048:\n",
    "            question = row['question']\n",
    "        d['prompt'] = f\"{question} ->\"\n",
    "        d['completion'] = f\" {row['sparql_wikidata']} \\n\"\n",
    "        training_json.append(json.dumps(d))\n",
    "    if filename is None:\n",
    "        return training_json\n",
    "    with open(filename, 'w') as f:\n",
    "        for l in training_json:\n",
    "            f.write(l + '\\n')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600c72a-06e6-4ff7-b772-bac406338b86",
   "metadata": {},
   "source": [
    "Play with it a bit to see that it's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "988da926-2aa0-4a74-98a7-e0c437312cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_json = make_finetune_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bd7bc66-c15c-448a-94f8-755e906fdd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"prompt\": \"let me know lord in Greek mythology title has the word thestrus in it ->\", \"completion\": \" SELECT DISTINCT ?sbj ?sbj_label WHERE { ?sbj wdt:P31 wd:Q24434794 . ?sbj rdfs:label ?sbj_label . FILTER(CONTAINS(lcase(?sbj_label), \\'thestrus\\')) . FILTER (lang(?sbj_label) = \\'en\\') } LIMIT 25  \\\\n\"}',\n",
       " '{\"prompt\": \"Who is the {protein} for {physically interatomic with} of {fentanyl} ->\", \"completion\": \"  select distinct ?sbj where { ?sbj wdt:P129 wd:Q407541 . ?sbj wdt:P31 wd:Q8054 }  \\\\n\"}',\n",
       " '{\"prompt\": \"Which is the office held by head of the organisation of Autonomous University of Madrid? ->\", \"completion\": \" select distinct ?answer where { wd:Q788091 wdt:P2388 ?answer} \\\\n\"}',\n",
       " '{\"prompt\": \"Is Usain Bolt\\'s individual best rise to to 36.84? ->\", \"completion\": \" ASK WHERE { wd:Q1189 wdt:P2415 ?obj filter(?obj = 36.84) }  \\\\n\"}',\n",
       " '{\"prompt\": \"What is the unicameral legislative body in Azad Kashmir called? ->\", \"completion\": \"  select distinct ?obj where { wd:Q200130 wdt:P194 ?obj . ?obj wdt:P31 wd:Q37002670 }  \\\\n\"}']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_json[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b8191-d20f-4217-88b9-44b6f6f9613c",
   "metadata": {},
   "source": [
    "Now create a training file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2398b15d-920b-448b-9eca-e437e0e5005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_train_file_name(N=5):\n",
    "    random_s = ''.join(random.choices(string.ascii_uppercase + string.digits, k=N))    \n",
    "    return f'openai_train_{random_s}.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66c33651-7da3-4c84-9347-9723c7f209ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_name = random_train_file_name()\n",
    "make_finetune_data(df_train, filename=train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3ee9f50-975e-4ee3-a9ae-cb729444161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file_name = random_train_file_name()\n",
    "make_finetune_data(df_validate, filename=validation_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c3ae3-22a2-475a-aaf6-776115d0868b",
   "metadata": {},
   "source": [
    "We hope that this call simply asserts that everything looks good - it should not prompt. If it prompts, it will crash because \n",
    "we're taking input from /dev/null. If you see a crash, try running this command in a shell, without the /dev/null prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c204e03-3f97-4a2b-a474-4c8bb9730aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 1000 prompt-completion pairs\n",
      "- All prompts end with suffix ` ->`\n",
      "- All completions end with suffix ` \\n`\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"openai_train_A7MUW.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" \\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 16.18 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f {train_file_name} < /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cacbaeb2-b388-4e4d-afd0-5be4fcd6d68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 200 prompt-completion pairs\n",
      "- All prompts end with suffix ` ->`\n",
      "- All completions end with suffix ` \\n`\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"openai_train_LVYWD.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" \\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 5.19 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f {validation_file_name} < /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf3431a-a784-4009-bcc5-55b8eb06aeb5",
   "metadata": {},
   "source": [
    "Now we create the training run. Note that many more hyperparameters can be specified. See https://platform.openai.com/docs/guides/fine-tuning/hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417c650-bfe2-44c3-8d8f-107f8c66c108",
   "metadata": {},
   "source": [
    "### Create the fine-tuning run\n",
    "In principal, this command creates the job and streams back the messages. In practice, I always see `Stream interrupted (client disconnected)` when I run it in a jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee2cf14f-348c-4883-9382-dc9974bb45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this if you don't want validation - but who doesn't want validation?\n",
    "#!openai api fine_tunes.create -t {train_file_name} -m {base_model} < /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd83d841-8cdf-4660-993e-af87a884b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 192k/192k [00:00<00:00, 89.9Mit/s]\n",
      "Uploaded file from openai_train_A7MUW.jsonl: file-EOYCkdbjT5gSAFON3lOWvgtP\n",
      "Found potentially duplicated files with name 'openai_train_A7MUW.jsonl', purpose 'fine-tune' and size 191887 bytes\n",
      "file-EOYCkdbjT5gSAFON3lOWvgtP\n",
      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 192k/192k [00:00<00:00, 92.7Mit/s]is file anyway: \n",
      "Uploaded file from openai_train_A7MUW.jsonl: file-IAkxwi534qhwZk0JuHgHk6SA\n",
      "Created fine-tune: ft-iVdTcCTmIoSHQ8VTVEkxa5aL\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-03-12 17:33:15] Created fine-tune: ft-iVdTcCTmIoSHQ8VTVEkxa5aL\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-iVdTcCTmIoSHQ8VTVEkxa5aL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use this if you do want validation\n",
    "\n",
    "!openai api fine_tunes.create -t {train_file_name} -v {train_file_name} -m {base_model} < /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3404dd1-2f40-41c4-89fa-cbfb1258f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_run_id():\n",
    "    result = subprocess.run(['openai','api', 'fine_tunes.list'], stdout=subprocess.PIPE)\n",
    "    runs = json.loads(result.stdout)\n",
    "    last_run = runs['data'][-1]\n",
    "    run_id = fine_tuned_model = None\n",
    "    if 'id' in last_run:\n",
    "        run_id = last_run['id']\n",
    "    if 'fine_tuned_model' in last_run:\n",
    "        fine_tuned_model = last_run['fine_tuned_model']  \n",
    "    return run_id, fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3739939f-3955-4c58-ade2-1976e0cfa9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ft-iVdTcCTmIoSHQ8VTVEkxa5aL', None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_run, fine_tuned_model = get_last_run_id()\n",
    "last_run, fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0282619-0adf-48c7-828c-f46a501a7d7c",
   "metadata": {},
   "source": [
    "Again, this command in principal streams all messages until completion, but in practice, also times out.\n",
    "\n",
    "So run this cell over and over until you see \"Status: succeeded ðŸŽ‰\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dcd9db0a-43d4-4fbd-87f8-2c3b0792ebed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-12 17:33:15] Created fine-tune: ft-iVdTcCTmIoSHQ8VTVEkxa5aL\n",
      "[2023-03-12 17:37:56] Fine-tune costs $7.09\n",
      "[2023-03-12 17:37:57] Fine-tune enqueued. Queue number: 0\n",
      "[2023-03-12 17:37:57] Fine-tune is in the queue. Queue number: 0\n",
      "[2023-03-12 17:37:59] Fine-tune started\n",
      "[2023-03-12 17:51:10] Completed epoch 1/4\n",
      "[2023-03-12 18:01:06] Completed epoch 2/4\n",
      "[2023-03-12 18:10:58] Completed epoch 3/4\n",
      "[2023-03-12 18:20:53] Completed epoch 4/4\n",
      "[2023-03-12 18:21:40] Uploaded model: davinci:ft-askwiki-2023-03-13-01-21-40\n",
      "[2023-03-12 18:21:42] Uploaded result file: file-Nm0MnsOcT72zCTqgLdMBo1HU\n",
      "[2023-03-12 18:21:42] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m davinci:ft-askwiki-2023-03-13-01-21-40 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i {last_run} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66c296-107b-42bf-9a00-9de7dd54c5c5",
   "metadata": {},
   "source": [
    "Get the fine-tuned model name. Make sure it's not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04b88200-c0da-4499-a6d7-145cfb2e1d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ft-iVdTcCTmIoSHQ8VTVEkxa5aL', 'davinci:ft-askwiki-2023-03-13-01-21-40')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_run, fine_tuned_model = get_last_run_id()\n",
    "last_run, fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1f947-c890-4590-86f2-049cfcaa67a3",
   "metadata": {},
   "source": [
    "Take a look at a few questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a190a06c-d141-4f14-9579-f714ec4f7c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' SELECT ?answer WHERE { wd:Q122467 wdt:P166 ?X . ?X wdt:P1056 ?answer}'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = run_prompt(\"What is Delta Air Line's periodical literature mouthpiece? ->\", \n",
    "                      model=fine_tuned_model, stop=[\" \\n\"])\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f9a945cb-55e7-4036-80d4-b00cd4279c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What grant was gotten Mary Tyler Moore ?'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcquad_df.iloc[sample_size+5]['paraphrased_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8ef9b7ba-b5c5-4cea-8fa5-eae2aedd3458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6sy3clKE6EimrIaY3FX4sKJgb5FtV at 0x7f8af2ecc130> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" SELECT ?value WHERE { wd:Q1680 p:P1082 ?s . ?s ps:P1082 ?x filter(contains(YEAR(?x),'1966')) . ?s pq:P585 ?value}\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1678558592,\n",
       "  \"id\": \"cmpl-6sy3clKE6EimrIaY3FX4sKJgb5FtV\",\n",
       "  \"model\": \"curie:ft-personal-2023-03-11-18-13-24\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 54,\n",
       "    \"prompt_tokens\": 9,\n",
       "    \"total_tokens\": 63\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = run_prompt(f\"{lcquad_df.iloc[sample_size+5]['paraphrased_question']} ->\", \n",
    "                      model=fine_tuned_model, stop=[\" \\n\"])\n",
    "response['choices'][0]['text']\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398ca3d-6a49-48a9-85de-57ea1eddc43c",
   "metadata": {},
   "source": [
    "### Fine-tune further if you want\n",
    "You just do the same things as above, but specify the fine-tuned model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0d6b46ad-dfcf-48e1-bac2-8c68934ef290",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_sample_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9077bf23-bdc9-4ad6-808a-16f8dd842f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_train_file_name = random_train_file_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f9908abf-1a76-4dc0-a2cf-9f1d334746fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_finetune_data(lcquad_df.iloc[sample_size:sample_size+next_sample_size], filename=next_train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "913c48d2-2a1f-423d-bce9-e6d593492cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 1000 prompt-completion pairs\n",
      "- All prompts end with suffix ` ->`\n",
      "- All completions end with suffix ` \\n`\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"openai_train_8YJQN.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" \\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 16.18 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f {next_train_file_name} < /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ca280-b480-451f-8270-cf32aa789ecc",
   "metadata": {},
   "source": [
    "#### Note: we're using the fine_tuned_model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "11fd4ef2-3d4f-4f84-b705-ebd8ab4eb834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found potentially duplicated files with name 'openai_train_RN5E2.jsonl', purpose 'fine-tune' and size 38794 bytes\n",
      "file-wqHZIMQlqYKdRnFS4Oj93nwl\n",
      "Upload progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38.8k/38.8k [00:00<00:00, 44.3Mit/s]is file anyway: \n",
      "Uploaded file from openai_train_RN5E2.jsonl: file-UrT9q5sOdsOC9gWUDYNChsQz\n",
      "Created fine-tune: ft-IR6C0jd8iTkdNRytnzutzuDd\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-03-11 11:16:50] Created fine-tune: ft-IR6C0jd8iTkdNRytnzutzuDd\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-IR6C0jd8iTkdNRytnzutzuDd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t {train_file_name} -m {fine_tuned_model} < /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "11fd76c8-1ef8-410e-95fa-e775fdf4ebe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ft-IR6C0jd8iTkdNRytnzutzuDd', None)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_run, fine_tuned_model = get_last_run_id()\n",
    "last_run, fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ab045-dd58-45cc-a403-54f5d2436ac9",
   "metadata": {},
   "source": [
    "Again, run this cell until you see the success message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fac08ffc-de84-4895-a635-0c8d275a2eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-11 11:16:50] Created fine-tune: ft-IR6C0jd8iTkdNRytnzutzuDd\n",
      "[2023-03-11 11:19:57] Fine-tune costs $0.15\n",
      "[2023-03-11 11:19:57] Fine-tune enqueued. Queue number: 0\n",
      "[2023-03-11 11:19:59] Fine-tune started\n",
      "[2023-03-11 11:21:39] Completed epoch 1/4\n",
      "[2023-03-11 11:22:17] Completed epoch 2/4\n",
      "[2023-03-11 11:22:55] Completed epoch 3/4\n",
      "[2023-03-11 11:23:33] Completed epoch 4/4\n",
      "[2023-03-11 11:23:51] Uploaded model: curie:ft-personal-2023-03-11-18-23-51\n",
      "[2023-03-11 11:23:52] Uploaded result file: file-Tdl2avROfPtZcHwjvmx3em9V\n",
      "[2023-03-11 11:23:52] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m curie:ft-personal-2023-03-11-18-23-51 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i {last_run} < /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6f3a1-a717-4f2a-a3db-7cf80e67b9d9",
   "metadata": {},
   "source": [
    "Pick up the fine-tuned model name. Note: this model was trained from the previous fine-tuned model, but this one has a different, new name.\n",
    "Presumably, the previous fine-tunesd model is still around. I'm not sure how to delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "17314c5c-4581-4aaa-9f8f-5070f987e77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ft-IR6C0jd8iTkdNRytnzutzuDd', 'curie:ft-personal-2023-03-11-18-23-51')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_run, fine_tuned_model = get_last_run_id()\n",
    "last_run, fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b25378-6604-4292-b536-6c9697af890b",
   "metadata": {},
   "source": [
    "### Sync with wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78db76a-cdb0-4f7f-ab07-442fdcd41ddf",
   "metadata": {},
   "source": [
    "You may need a paid openai account for this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c63d3a7-bd3e-422d-8c98-590942561cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'nl2sparql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07dc580b-aa82-4998-a194-9d6ef2f30f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/simple, https://artifactory.concurtech.net/artifactory/api/pypi/ext-pypi-selfserve-local/simple\n",
      "Collecting wandb\n",
      "  Downloading https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/packages/packages/7f/7d/6be3f2da29b80ad650d624f2bb6b76814a25aafa17260d7efbe3b5e0ccd3/wandb-0.13.11-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from wandb) (5.9.0)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/packages/packages/e4/03/4a3e03619eb41b4d9028d377869cc29a5a2095975ca9e8d9b64cb87e1450/sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from wandb) (4.3.0)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/packages/packages/9e/8a/d1e02cc111d65b0346f70abb83c51f8593e7134bf694a4a56d1a470caaf7/GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading https://artifactory.concurtech.net/artifactory/api/pypi/ext-pypi-selfserve-local/docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from wandb) (63.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from wandb) (2.28.1)\n",
      "Collecting setproctitle\n",
      "  Downloading https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/packages/packages/50/ef/cff921345cadf05bef3cb4da37eac23d08fd063222a633231e8ae1f61a0d/setproctitle-1.3.2-cp39-cp39-macosx_10_9_universal2.whl (16 kB)\n",
      "Collecting pathtools\n",
      "  Downloading https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/packages/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,<5,>=3.19.0\n",
      "  Downloading https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/packages/packages/fa/09/c9b6d85a65c37a04f7c5f63ca28d143d127c0394b70ba1b419b2d0646e75/protobuf-4.22.1-cp37-abi3-macosx_10_9_universal2.whl (397 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m397.2/397.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: PyYAML in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/packages/packages/21/a6/35f83efec687615c711fe0a09b67e58f6d1254db27b1013119de46f450bd/gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m972.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached https://artifactory.concurtech.net/artifactory/api/pypi/pypi.python.org/packages/packages/6d/01/7caa71608bc29952ae09b0be63a539e50d2484bc37747797a66a60679856/smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=2e14e7ed9e67c54b4b601255365bf88d6f6f1f68d86c499526d0385e1b954331\n",
      "  Stored in directory: /Users/i857913/Library/Caches/pip/wheels/fe/dc/4f/e15d69c7fca993da720256f833311a0f48ddce31c786461d02\n",
      "Successfully built pathtools\n",
      "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 protobuf-4.22.1 sentry-sdk-1.16.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.13.11\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1de4dd1a-28f5-47c9-adb6-7b63cda73717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaziff-berkeley\u001b[0m (\u001b[33maskwiki\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/i857913/Documents/mids/210/kgqa-ucb-210/training/wandb/run-20230313_133004-ft-iVdTcCTmIoSHQ8VTVEkxa5aL\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mft-iVdTcCTmIoSHQ8VTVEkxa5aL\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/askwiki/nl2sparql\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/askwiki/nl2sparql/runs/ft-iVdTcCTmIoSHQ8VTVEkxa5aL\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             elapsed_examples â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               elapsed_tokens â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                training_loss â–‡â–„â–†â–‡â–‡â–†â–‡â–„â–‡â–ƒâ–‡â–‡â–„â–ˆâ–„â–ƒâ–‚â–„â–ƒâ–†â–â–…â–ƒâ–…â–…â–ƒâ–„â–†â–‚â–â–‚â–„â–„â–‚â–‚â–ƒâ–„â–…â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   training_sequence_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      training_token_accuracy â–â–†â–…â–…â–„â–†â–…â–†â–†â–‡â–…â–„â–†â–„â–…â–‡â–‡â–†â–‡â–„â–ˆâ–†â–‡â–„â–…â–‡â–†â–†â–‡â–ˆâ–ˆâ–‡â–†â–ˆâ–‡â–‡â–†â–†â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              validation_loss â–ˆâ–‚â–„â–‚â–„â–â–â–„â–„â–…â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–â–ƒâ–…â–„â–â–‚â–‚â–â–ƒâ–â–„â–„â–‚â–â–â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: validation_sequence_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    validation_token_accuracy â–â–†â–…â–‡â–„â–‡â–‡â–„â–…â–…â–‡â–†â–†â–†â–‡â–†â–ˆâ–‡â–†â–„â–†â–‡â–‡â–‡â–‡â–†â–ˆâ–†â–…â–‡â–†â–‡â–…â–…â–†â–†â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             elapsed_examples 4002.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               elapsed_tokens 294194.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             fine_tuned_model davinci:ft-askwiki-2...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       status succeeded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                training_loss 0.15772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   training_sequence_accuracy 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      training_token_accuracy 0.94215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              validation_loss 0.44964\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: validation_sequence_accuracy 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    validation_token_accuracy 0.87037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mft-iVdTcCTmIoSHQ8VTVEkxa5aL\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/askwiki/nl2sparql/runs/ft-iVdTcCTmIoSHQ8VTVEkxa5aL\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230313_133004-ft-iVdTcCTmIoSHQ8VTVEkxa5aL/logs\u001b[0m\n",
      "ðŸŽ‰ wandb sync completed successfully\n"
     ]
    }
   ],
   "source": [
    "!WANDB_API_KEY=`cat secrets.ini | grep WANDB_API_KEY | sed 's/^WANDB_API_KEY=//'` openai wandb sync --project {project_name} < /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed453bb-90c4-40d9-94a1-d5f54fc86e13",
   "metadata": {},
   "source": [
    "## Check syntactic correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d178cc5c-a5d3-488b-afa2-4f07bb2c8296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_sparql(question, model=base_model, stop=None):\n",
    "    response = run_prompt(f\"{question} ->\", model=model, stop=stop)\n",
    "    # print(response)\n",
    "    translation = response['choices'][0]['text']\n",
    "    # print(translation)\n",
    "    if translation is None or len(translation) == 0:\n",
    "        return None\n",
    "    # logging.info(f'sparql {translation}')\n",
    "    return translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2ef96671-73f8-46ea-82c8-35d869f441f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' select distinct ?answer where { wd:Q974 wdt:P24 ?answer}'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sparql(\"What is the name of Bill Gate's mother?\", model=fine_tuned_model, stop=[\" \\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4263016d-6e47-46c9-99f0-7d89f1e488e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lots_of_sparql(l, generator=None):\n",
    "    result = []\n",
    "    count = 1\n",
    "    if generator is None:\n",
    "        generator = lambda s: generate_sparql(s)\n",
    "    for s in l:\n",
    "        if count % 10 == 0:\n",
    "            print(count)\n",
    "        result.append(generator(s))\n",
    "        count += 1\n",
    "    print(count-1)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "518c85d4-05b8-4ada-8db3-78ec8f3d06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = lambda s: generate_sparql(s, model=fine_tuned_model, stop=[\" \\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "728583a0-d976-4e9c-9d3c-f3aee8690225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' select distinct ?answer where { wd:Q355444 wdt:P3822 ?answer}'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"What is the name of Bill Gate's mother?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "22581ebd-3a83-4d0b-9627-5391a9f6e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "sparqls = generate_lots_of_sparql(lcquad_df[-10: -1]['question'], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e2303ee6-a7a7-4121-9980-ea1879635d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" SELECT ?answer WHERE { wd:Q128056 wdt:P180 ?answer . ?answer wdt:P1279 ?x FILTER(contains(?x,'Al Green'))}\",\n",
       " ' ASK WHERE { wd:Q252 wdt:P741 ?obj filter(?obj = 45.6) } ',\n",
       " ' SELECT ?answer WHERE { wd:Q171741 wdt:P19 ?X . ?X wdt:P19 ?answer}',\n",
       " ' SELECT ?answer WHERE { wd:Q1628086 wdt:P26 ?answer . ?answer wdt:P190 wd:Q133642}',\n",
       " \" SELECT DISTINCT ?sbj ?sbj_label WHERE { ?sbj wdt:P31 wd:Q43229 . ?sbj rdfs:label ?sbj_label . FILTER(CONTAINS(lcase(?sbj_label), 's')) . FILTER (lang(?sbj_label) = 'en') } LIMIT 25 \",\n",
       " \" SELECT DISTINCT ?sbj ?sbj_label WHERE { ?sbj wdt:P31 wd:Q109 . ?sbj rdfs:label ?sbj_label . FILTER(STRSTARTS(lcase(?sbj_label), 'H')) . FILTER (lang(?sbj_label) = 'en') } LIMIT 25 \",\n",
       " ' ASK WHERE { wd:Q742408 wdt:P2260 ?obj filter(?obj = 117.6) } ',\n",
       " ' SELECT ?answer WHERE { wd:Q65984 wdt:P108 ?X . ?X wdt:P103 ?answer}',\n",
       " ' SELECT ?obj WHERE { wd:Q1101377 p:P1082 ?s . ?s ps:P1082 ?obj . ?s pq:P459 wd:Q1344910 }']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparqls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "46a9c065-39f3-4862-b0fb-50e9529ecf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikibaseintegrator import wbi_helpers\n",
    "from wikibaseintegrator.wbi_config import config as wbi_config\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "710b6bcb-5e1c-449b-a22f-f80ed78c199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbi_config['USER_AGENT'] = 'AskwikiBot/1.0 (https://www.wikidata.org/wiki/User:What_Tottles_Meant)'\n",
    "wbi_config['BACKOFF_MAX_TRIES'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9f71ac3d-26c9-43a9-97fd-e13731767bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.exceptions import HTTPError\n",
    "def run_sparql(query):\n",
    "    try:\n",
    "        results = wbi_helpers.execute_sparql_query(query)\n",
    "    except HTTPError as he:\n",
    "        logging.error(f'HTTPError {he}')\n",
    "        print(f\"failed query {query}\")\n",
    "        return None\n",
    "    # print(results)\n",
    "    if 'boolean' in results:\n",
    "        return pd.DataFrame([{'Boolean': results['boolean'] }])\n",
    "    jsonResult = [dict([(k, b[k]['value']) for k in b]) for b in results['results']['bindings']]\n",
    "    df = pd.DataFrame.from_dict(jsonResult)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8ed0e78c-61e0-4421-85f3-d373110ab733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_queries(qs):\n",
    "    validation_results = []\n",
    "    count = 0\n",
    "    for q in qs:\n",
    "        # print(q)\n",
    "        df = run_sparql(q)\n",
    "        result_count = 0\n",
    "        if df is None:\n",
    "            run_result = 'Fail'\n",
    "            print(f\"Failed query number {count}\")\n",
    "        else:\n",
    "            run_result = 'Pass'\n",
    "            result_count = len(df)\n",
    "        validation_results.append((run_result, result_count))\n",
    "        count += 1\n",
    "    return validation_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "de5a08bd-cdc1-4a93-a188-c9acaff77b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pass', 0),\n",
       " ('Pass', 1),\n",
       " ('Pass', 0),\n",
       " ('Pass', 0),\n",
       " ('Pass', 25),\n",
       " ('Pass', 0),\n",
       " ('Pass', 1),\n",
       " ('Pass', 0),\n",
       " ('Pass', 0)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_queries(sparqls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1b742579-180f-4832-935a-5163779a7d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "sparqls = generate_lots_of_sparql(lcquad_df[0: 10]['question'], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5bd300c3-9ee6-4869-801f-33028223c1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:backoff:Giving up execute_sparql_query(...) after 1 tries (requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql?query=%23Tool%3A+WikibaseIntegrator+wbi_functions.execute_sparql_query%0A+ASK+WHERE+%7B+wd%3AQ7424+wdt%3AP27+wd%3AQ56474+.+wd%3AQ7424+wdt%3AP27+wd%3AQ56474+not%28ber%3ASTARTING_VALUE151398%29+%7D+&format=json)\n",
      "ERROR:root:HTTPError 400 Client Error: Bad Request for url: https://query.wikidata.org/sparql?query=%23Tool%3A+WikibaseIntegrator+wbi_functions.execute_sparql_query%0A+ASK+WHERE+%7B+wd%3AQ7424+wdt%3AP27+wd%3AQ56474+.+wd%3AQ7424+wdt%3AP27+wd%3AQ56474+not%28ber%3ASTARTING_VALUE151398%29+%7D+&format=json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed query  ASK WHERE { wd:Q7424 wdt:P27 wd:Q56474 . wd:Q7424 wdt:P27 wd:Q56474 not(ber:STARTING_VALUE151398) } \n",
      "Failed query number 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Pass', 0),\n",
       " ('Pass', 0),\n",
       " ('Pass', 1),\n",
       " ('Pass', 0),\n",
       " ('Pass', 0),\n",
       " ('Pass', 25),\n",
       " ('Fail', 0),\n",
       " ('Pass', 0),\n",
       " ('Pass', 1),\n",
       " ('Pass', 0)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_queries(sparqls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "132ae541-7cfa-4654-9ea8-705ed4917e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' SELECT ?answer WHERE { wd:Q168790 wdt:P172 ?answer . ?answer wdt:P571 wd:Q168790}',\n",
       " ' SELECT ?answer WHERE { wd:Q169794 wdt:P156 ?X . ?X wdt:P1346 ?answer}',\n",
       " ' ASK WHERE { wd:Q4092 wdt:P1337 wd:Q106697 . wd:Q4092 wdt:P1337 wd:Q152697 }',\n",
       " \" SELECT ?answer WHERE { wd:Q162856 wdt:P186 ?answer . ?answer wdt:P2080 ?x FILTER(contains(?x,'phase_matter_of_Galinstan'))}\",\n",
       " ' select distinct ?answer where { wd:Q32491 wdt:P2260 ?answer}',\n",
       " \" SELECT DISTINCT ?sbj ?sbj_label WHERE { ?sbj wdt:P31 wd:Q23847174 . ?sbj rdfs:label ?sbj_label . FILTER(STRSTARTS(lcase(?sbj_label), 'p')) . FILTER (lang(?sbj_label) = 'en') } LIMIT 25 \",\n",
       " ' ASK WHERE { wd:Q7424 wdt:P27 wd:Q56474 . wd:Q7424 wdt:P27 wd:Q56474 not(ber:STARTING_VALUE151398) } ',\n",
       " '  select distinct ?obj where { wd:Q202729 wdt:P358 ?obj . ?obj wdt:P31 wd:Q273057 } ',\n",
       " ' select distinct ?answer where { wd:Q235975 wdt:P3171 ?answer}',\n",
       " ' SELECT ?answer WHERE { wd:Q1159316 wdt:P156 ?X . ?X wdt:P1346 ?answer}']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparqls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a5579566-14ca-4cd8-9ce7-08337d57a3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     select distinct ?obj where { wd:Q188920 wdt:P...\n",
       "1    SELECT ?answer WHERE { wd:Q169794 wdt:P26 ?X ....\n",
       "2    ASK WHERE { wd:Q174843 wdt:P106 wd:Q1804811 . ...\n",
       "3    SELECT ?answer WHERE { wd:Q675176 wdt:P515 ?X ...\n",
       "4    select distinct ?answer where { wd:Q32491 wdt:...\n",
       "5    SELECT DISTINCT ?sbj ?sbj_label WHERE { ?sbj w...\n",
       "6    ASK WHERE { wd:Q4180017 wdt:P6257 ?obj filter(...\n",
       "7     select distinct ?obj where { wd:Q202729 wdt:P...\n",
       "8    select distinct ?answer where { wd:Q235975 wdt...\n",
       "9    SELECT ?answer WHERE { wd:Q1356316 wdt:P156 ?X...\n",
       "Name: sparql_wikidata, dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcquad_df[0:10]['sparql_wikidata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c1504f4e-e748-4017-bfe6-bdde6a8d1e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pass', 1),\n",
       " ('Pass', 1),\n",
       " ('Pass', 1),\n",
       " ('Pass', 0),\n",
       " ('Pass', 1),\n",
       " ('Pass', 0),\n",
       " ('Pass', 1),\n",
       " ('Pass', 0),\n",
       " ('Pass', 1),\n",
       " ('Pass', 1)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_queries(lcquad_df[0:10]['sparql_wikidata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "af8af267-a48a-4a9a-8845-af8af61fbf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What range are the papers at the Monique Genonceaux about?'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcquad_df.iloc[3]['paraphrased_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bcf01a64-c037-49c7-a8bc-fcadc9326c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT ?answer WHERE { wd:Q675176 wdt:P515 ?X . ?X wdt:P156 ?answer}'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcquad_df.iloc[3]['sparql_wikidata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8614cb98-0565-492f-9461-dc077e56c9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" SELECT ?answer WHERE { wd:Q162856 wdt:P186 ?answer . ?answer wdt:P2080 ?x FILTER(contains(?x,'phase_matter_of_Galinstan'))}\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparqls[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0a0bcacf-4a10-4f2e-9737-5a068a0f2e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNQT_question           Does the {right ascension} of the {Malin 1} {l...\n",
       "uid                                                                 18423\n",
       "subgraph                                              boolean with filter\n",
       "template_index                                                        441\n",
       "question                Is the right ascension of malin 1 less than 15...\n",
       "sparql_wikidata         ASK WHERE { wd:Q4180017 wdt:P6257 ?obj filter(...\n",
       "sparql_dbpedia18        ASK { ?statement1 <http://www.w3.org/1999/02/2...\n",
       "template                            ASK ?sbj ?pred ?obj filter ?obj = num\n",
       "answer                                                                 []\n",
       "template_id                                                             3\n",
       "paraphrased_question    Does malin 1 have a right ascension lower than...\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcquad_df.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a579aa12-1088-4b42-8872-d017d25d037e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does malin 1 have a right ascension lower than 15.1398?'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcquad_df.iloc[6]['paraphrased_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749c8c1-caeb-4717-a453-0ed35fe488c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda210",
   "language": "python",
   "name": "conda210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
